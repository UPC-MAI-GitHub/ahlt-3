{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NERC Project for Recognizing and Classifying Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "from os import listdir\n",
    "from xml.dom.minidom import parse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mponsclo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mponsclo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence examples\n",
    "sent_1 = \"Activation of an effector immediate-early gene arc by methamphetamine\"\n",
    "sent_2 = \"In situations in which concurrent therapy is necessary, careful patient monitoring is essential.\"\n",
    "sent_3 = \"Phenothiazines and butyrophenones may reduce or reverse the pressor effect of epinephrine.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Activation', 'of', 'an', 'effector', 'immediate-early', 'gene', 'arc', 'by', 'methamphetamine']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize word\n",
    "tokenized_sent_1 = word_tokenize(sent_1)\n",
    "tokenized_sent_2 = word_tokenize(sent_2)\n",
    "print(tokenized_sent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OffsetFrom: 0\n",
      "OffsetTo: 9\n",
      "\n",
      "OffsetFrom: 3\n",
      "OffsetTo: 12\n"
     ]
    }
   ],
   "source": [
    "# Use the .find() method to find offset and end position\n",
    "print(\"OffsetFrom: \" + str(sent_1.find(tokenized_sent_1[0]))) # offset\n",
    "print(\"OffsetTo: \" + str(sent_1.find(tokenized_sent_1[0]) + len(tokenized_sent_1[0]) - 1)) # end\n",
    "print(\"\")\n",
    "print(\"OffsetFrom: \" + str(sent_2.find(tokenized_sent_2[1]))) # offset\n",
    "print(\"OffsetTo: \" + str(sent_2.find(tokenized_sent_2[1]) + len(tokenized_sent_2[1]) - 1)) # end\n",
    "\n",
    "# From this results generate desired output: list of tuples (word, offsetFrom, offsetTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Activation', 'of', 'an', 'effector', 'immediate-early', 'gene', 'arc', 'by', 'methamphetamine']\n",
      "Filterd Sentence: ['Activation', 'effector', 'gene', 'arc', 'methamphetamine']\n"
     ]
    }
   ],
   "source": [
    "# Removing Stopwords and Punctuations to Reduce Workload\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_sent = []\n",
    "\n",
    "for w in tokenized_sent_1:\n",
    "    if (w not in stop_words) & (w.isalpha()):\n",
    "        filtered_sent.append(w)\n",
    "\n",
    "print(\"Tokenized Sentence:\",tokenized_sent_1)\n",
    "print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "tokens = []\n",
    "for t in tokenized_word_1:\n",
    "    offset = sent_1.find(t, offset)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    '''\n",
    "    Given a sentence , calls nltk.tokenize to split it in tokens, and adds to each token its start / end offset \n",
    "    in the original sentence .\n",
    "    Input - s: string containing the text for one sentence\n",
    "    Output - Returns a list of tuples (word , offsetFrom , offsetTo )'''\n",
    "\n",
    "    token_list = []\n",
    "    tokens = word_tokenize(s)\n",
    "    \n",
    "    for t in tokens:\n",
    "        if (t in stop_words) & (not t.isalpha()):\n",
    "            continue\n",
    "        else:\n",
    "            offsetFrom = s.find(t)\n",
    "            offsetTo = offsetFrom + len(t) - 1\n",
    "            token_list.append((t, offsetFrom, offsetTo))\n",
    "            \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Activation', 0, 9),\n",
       " ('of', 11, 12),\n",
       " ('an', 14, 15),\n",
       " ('effector', 17, 24),\n",
       " ('immediate-early', 26, 40),\n",
       " ('gene', 42, 45),\n",
       " ('arc', 47, 49),\n",
       " ('by', 51, 52),\n",
       " ('methamphetamine', 54, 68)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Activation of an effector immediate-early gene arc by methamphetamine\"\n",
    "tokenize(sent_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine (by hand or collecting simple statistics) the train dataset and try to infer general rules that are right in most cases, even if they seldom apply (high precision, low recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "datadir = \"/Users/mponsclo/Documents/DataScience/ALHT_Project/train\"\n",
    "df = pd.DataFrame() # initialize Data Frame\n",
    "\n",
    "for f in listdir(datadir):\n",
    "        try:\n",
    "            filename = datadir + \"/\" + f\n",
    "            tree = ET.parse(filename) # Some file rose an error when parsing\n",
    "            root = tree.getroot()\n",
    "        \n",
    "            for elem in root:\n",
    "                for subelem in elem.findall('entity'):\n",
    "                    aux_df = pd.DataFrame({'Name': subelem.get('text'), 'Type': subelem.get('type')}, index=[0])\n",
    "                    df = df.append(aux_df)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>warfarin</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digoxin</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenytoin</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theophylline</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lithium</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ketoconazole</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cimetidine</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclosporine</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbamazepine</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rifampin</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erythromycin</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methotrexate</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluoxetine</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenobarbital</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morphine</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aprepitant</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fluvoxamine</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propranolol</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probenecid</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diltiazem</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vardenafil</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itraconazole</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allopurinol</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ketoconazole</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quinidine</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alprazolam</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nifedipine</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolbutamide</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diazepam</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terfenadine</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midazolam</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethanol</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diflunisal</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaminophen</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>succinylcholine</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heparin</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gabapentin</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isoniazid</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ritonavir</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacrolimus</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarithromycin</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furosemide</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cisapride</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citalopram</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phenytoin</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atorvastatin</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaleplon</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norepinephrine</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Count\n",
       "warfarin           167\n",
       "digoxin            145\n",
       "phenytoin          141\n",
       "theophylline        99\n",
       "lithium             94\n",
       "ketoconazole        91\n",
       "alcohol             90\n",
       "cimetidine          70\n",
       "cyclosporine        70\n",
       "carbamazepine       69\n",
       "rifampin            57\n",
       "erythromycin        57\n",
       "methotrexate        54\n",
       "fluoxetine          48\n",
       "phenobarbital       46\n",
       "morphine            45\n",
       "Aprepitant          42\n",
       "fluvoxamine         40\n",
       "insulin             38\n",
       "propranolol         36\n",
       "probenecid          34\n",
       "diltiazem           34\n",
       "Vardenafil          34\n",
       "itraconazole        34\n",
       "allopurinol         33\n",
       "Ketoconazole        32\n",
       "quinidine           32\n",
       "alprazolam          31\n",
       "nifedipine          31\n",
       "tolbutamide         31\n",
       "diazepam            30\n",
       "terfenadine         30\n",
       "midazolam           30\n",
       "ethanol             29\n",
       "diflunisal          28\n",
       "acetaminophen       28\n",
       "succinylcholine     27\n",
       "heparin             26\n",
       "gabapentin          26\n",
       "isoniazid           26\n",
       "ritonavir           26\n",
       "tacrolimus          25\n",
       "clarithromycin      25\n",
       "furosemide          25\n",
       "cisapride           25\n",
       "citalopram          25\n",
       "Phenytoin           25\n",
       "atorvastatin        25\n",
       "zaleplon            24\n",
       "norepinephrine      24"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis of Types\n",
    "# df.to_csv(\"/Users/mponsclo/Desktop/df.csv\", index=False) Save df as .csv\n",
    "\n",
    "group = df[df[\"Type\"] == \"group\"]\n",
    "brand = df[df[\"Type\"] == \"brand\"]\n",
    "drug = df[(df[\"Type\"]=='drug') | (df[\"Type\"]== \"drug_n\")]\n",
    "\n",
    "group_counts = pd.DataFrame(group['Name'].value_counts())\n",
    "brand_counts = pd.DataFrame(brand['Name'].value_counts())\n",
    "drug_counts = pd.DataFrame({'Count' : drug['Name'].value_counts()})\n",
    "\n",
    "\n",
    "#group_counts\n",
    "#brand_counts\n",
    "drug_counts.head()\n",
    "\n",
    "# ax = drug_counts[(drug_counts[\"Count\"] > 1)].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word.isupper(): return True, \"brand\"\n",
    "elif word[-5:] in ['azole ', 'idine ', 'amine ', 'mycin ']:\n",
    "    return True, \"drug\"\n",
    "else: return False, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(s):\n",
    "    ''' Given a tokenized sentence , identify which tokens (or groups of consecutive tokens) are drugs\n",
    "    Input - s: A tokenized sentence ( list of triples (word , offsetFrom , offsetTo ) )\n",
    "    Output - A list of entities. Each entity is a dictionary with the keys 'name ', ' offset ', and 'type '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(datadir, outfile):\n",
    "    '''datadir - directory with XML files\n",
    "       outfile - name for the outputfile'''\n",
    "\n",
    "    # process each file in directory\n",
    "    for f in listdir(datadir):\n",
    "        # parse XML file, obtaining a DOM tree\n",
    "        tree = parse(datadir + \"/\" + f)\n",
    "        # process each senetence in the file\n",
    "        sentences = tree.getElementsByTagName(\"sentence\")\n",
    "        for s in sentences:\n",
    "                sid = s.attributes[\"id\"].value        # get sentence id\n",
    "                stext = s.attributes[\"text\"].value    # get sentence text\n",
    "                # tokenize text\n",
    "                tokens = tokenize(stext)\n",
    "                # extract entities from tokenized sentence text\n",
    "                entities = extract_entities(tokens)\n",
    "\n",
    "                # print sentence entities in format requested for evaluation\n",
    "                for e in entities:\n",
    "                    print(sid + \"|\" + e[\"offset\"] + \"|\" + e[\"text\"] + \"|\" e[\"type\"], file = outf)\n",
    "        # print performance score\n",
    "        evaluator.evaluate(\"NER\", datadir, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the process of iteration through XML files in the folder\n",
    "datadir = \"/Users/mponsclo/Documents/DataScience/ALHT_Project/train\"\n",
    "for f in listdir(datadir):\n",
    "    filename = datadir + \"/\" + f\n",
    "    #print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entecavir</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BARACLUDE</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entecavir</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entecavir</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamivudine</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antidiabetic agents</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VELCADE</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>antidiabetic medication</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calcium</td>\n",
       "      <td>drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMCYT</td>\n",
       "      <td>brand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name   Type\n",
       "0                 entecavir   drug\n",
       "0                 BARACLUDE  brand\n",
       "0                 entecavir   drug\n",
       "0                 entecavir   drug\n",
       "0                lamivudine   drug\n",
       "..                      ...    ...\n",
       "0       antidiabetic agents  group\n",
       "0                   VELCADE  brand\n",
       "0   antidiabetic medication  group\n",
       "0                   calcium   drug\n",
       "0                     EMCYT  brand\n",
       "\n",
       "[1430 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction of the dataframe\n",
    "tree = ET.parse(\"/Users/mponsclo/Documents/DataScience/ALHT_Project/train/Estramustine_ddi.xml\")\n",
    "root = tree.getroot()\n",
    "    \n",
    "for elem in root:\n",
    "    for subelem in elem.findall('entity'):    \n",
    "        # if we know the name of the attribute, access it directly\n",
    "        # aux_dict = {\"text\":subelem.get('text'), \"type\":subelem.get('type')} # as a dict\n",
    "        \n",
    "        aux_df = pd.DataFrame({'Name': subelem.get('text'), 'Type': subelem.get('type')}, index=[0])\n",
    "        df = df.append(aux_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiriQ3",
   "language": "python",
   "name": "miriq3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
