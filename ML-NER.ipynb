{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor\n",
    "- Must be an independent program, separate from learner and classifier.\n",
    "- Must get as argument the directory with the XML files to encode. \n",
    "- Must print the feature vectors to `stdout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features\n",
    "Given a tokenized sentence, return a feature vector fo each token.\n",
    "Example :\n",
    "> `extract_features` ([(\" Ascorbic \" ,0 ,7) , (\" acid \" ,9 ,12) , (\" ,\" ,13 ,13) ,\n",
    "(\" aspirin \" ,15 ,21) , (\" ,\" ,22 ,22) , (\" and \" ,24 ,26) , (\" the \" ,28 ,30) ,\n",
    "(\" common \" ,32 ,37) , (\" cold \" ,39 ,42) , (\".\" ,43 ,43) ])\n",
    "[ [ \" form = Ascorbic \", \" suf4 = rbic \", \" next = acid \", \" prev = _BoS_ \", \"\n",
    "capitalized \" ],\n",
    "[ \" form = acid \", \" suf4 = acid \", \" next =,\", \" prev = Ascorbic \" ],\n",
    "[ \" form =,\", \" suf4 =,\", \" next = aspirin \", \" prev = acid \", \" punct \" ],\n",
    "[ \" form = aspirin \", \" suf4 = irin \", \" next =,\", \" prev =,\" ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(s):\n",
    "    '''\n",
    "    Input:\n",
    "        s: A tokenized sentence (list of triples (word, offsetFrom, offsetTo) )\n",
    "        \n",
    "    Output: \n",
    "        A list of feature vectors, one per token.\n",
    "        Features are binary and vectors are in sparse representeation (i.e. only active features are listed)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tag\n",
    "Given a token and a list of ground truth entities in a sentence, decide which is the B-I-O tag for the token.\n",
    "**B-I-O** Ap\n",
    "> `get_tag` ((\" Ascorbic \" ,0 ,7) , [(0 , 12, \" drug \") , (15 , 21, \" brand \") ]) --> B- drug\n",
    "\n",
    "> `get_tag` ((\" acid \" ,9 ,12) , [(0 , 12, \" drug \") , (15 , 21, \" brand \") ]) --> I- drug\n",
    "\n",
    "> `get_tag` ((\" common \" ,32 ,37) , [(0 , 12, \" drug \") , (15 , 21, \" brand \") ]) --> 0\n",
    "\n",
    "> `get_tag` ((\" aspirin \" ,15 ,21) , [(0 , 12, \" drug \") , (15 , 21, \" brand \") ]) --> B- brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(token, gold):\n",
    "    '''\n",
    "    Input:\n",
    "        token: A token, i.e. one triple (word, offsetFrom, offsetTo)\n",
    "        gold: A list of ground truth entities, i.e. a list of triples (offsetFrom, offsetTo, type)\n",
    "        \n",
    "    Output:\n",
    "        The B-I-O ground truth tag for the given token (\"B-drug\", \"I-drug\", \"B-group\", \"I-group\", \"O\", ...)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each file in directory\n",
    "for f in listdir(datadir):\n",
    "    # parse XML file, obtaining a DOM tree\n",
    "    tree = parse(datadir + \"/\" + f)\n",
    "    # process each sentence in the file\n",
    "    sentences = tree.getElementsByTagName(\"sentence\")\n",
    "    \n",
    "    for s in sentence:\n",
    "        sid = s.attributes[\"id\"].value # get sentence id\n",
    "        stext = s.attributes[\"text\"].value # get sentence text\n",
    "        # load ground truth entities\n",
    "        gold = []\n",
    "        entities = s.getElementsByTagNameByTagName(\"entity\")\n",
    "        for e in entities:\n",
    "            # for discontinuous entities, we only get the first span\n",
    "            offset = e.attributes[\"charOffset\"].value\n",
    "            (start, end) = offset.split(\":\")[0].split(\"-\")\n",
    "            gold.append((int(start), int(end), e.attributes[\"type\"].value))\n",
    "            \n",
    "        # tokenize text\n",
    "        tokens = tokenize(stext)\n",
    "        \n",
    "        #extract features for eac word in the sentence\n",
    "        features = extract_features(tokens)\n",
    "        \n",
    "        # print features in format suitable for the learner/classifier\n",
    "        for i in range (0, len(tokens)):\n",
    "            # see if the token is part of an entity, and which part (B/I)\n",
    "            tag = get_tag(tokens[i], gold)\n",
    "            print(sid, tokens[i][0], tokens[i][1], tokens[i][2], tag, \"\\t\".join(features[i]), sep='\\t')\n",
    "            \n",
    "        # black line to separate sentences\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-I-O Approach \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program that parses all XML files in the folder given as argument and recognizes and classifies drug names. The program must use a sequence tagging machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiriQ3",
   "language": "python",
   "name": "miriq3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
