{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "cd into ../stanford-corenlp-4.2.0 and run\n",
    "\n",
    "`java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.dom.minidom import parse\n",
    "# import nltk CoreNLP module (just once)\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "# connect to your CoreNLP server (just once)\n",
    "corenlp_parser = CoreNLPDependencyParser(url=\"http://localhost:9000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offsets(word, s):\n",
    "    '''\n",
    "    Task:\n",
    "        Given a word and sentence, returns its starting end ending index in the sentence.\n",
    "    \n",
    "    Input:\n",
    "        word: word to find offsets for\n",
    "        s: sentence containing the word\n",
    "    \n",
    "    Output:\n",
    "        Returns a tuple containing the start and end offset.\n",
    "    '''\n",
    "    start = s.find(word)\n",
    "    end = start + len(word) - 1\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    '''\n",
    "    Task:\n",
    "        Helper function\n",
    "    '''\n",
    "    # because otherwise CoreNLP throws 500\n",
    "    return s.replace(\"%\", \"<percentage>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(s):\n",
    "    '''\n",
    "    Task:\n",
    "        Given one sentence, sends it to CoreNLP to obtain the tokens, tags,\n",
    "        and dependency tree. It also adds the start/end offsets to each token.\n",
    "    \n",
    "    Input:\n",
    "        s: string containing the text for one sentence\n",
    "    \n",
    "    Output:\n",
    "        Returns the nltk DependencyGraph object produced by CoreNLP, enriched with token  offsets.\n",
    "\n",
    "    '''\n",
    "    s = preprocess(s)\n",
    "    tree, = corenlp_parser.raw_parse(s)\n",
    "    for n in tree.nodes.items():\n",
    "        node = n[1]\n",
    "        if node['word']:\n",
    "            start, end = get_offsets(node['word'], s)\n",
    "            node['start'] = start\n",
    "            node['end'] = end\n",
    "            \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, {'address': 0, 'word': None, 'lemma': None, 'ctag': 'TOP', 'tag': 'TOP', 'feats': None, 'head': None, 'deps': defaultdict(<class 'list'>, {'ROOT': [1]}), 'rel': None}), (1, {'address': 1, 'word': 'Co-administration', 'lemma': 'co-administration', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 0, 'deps': defaultdict(<class 'list'>, {'nmod': [4], 'dep': [13], 'punct': [41]}), 'rel': 'ROOT', 'start': 0, 'end': 16}), (2, {'address': 2, 'word': 'of', 'lemma': 'of', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 4, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 18, 'end': 19}), (4, {'address': 4, 'word': 'ketoconazole', 'lemma': 'ketoconazole', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 1, 'deps': defaultdict(<class 'list'>, {'case': [2], 'amod': [3]}), 'rel': 'nmod', 'start': 26, 'end': 37}), (3, {'address': 3, 'word': 'oral', 'lemma': 'oral', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 4, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 21, 'end': 24}), (5, {'address': 5, 'word': '200', 'lemma': '200', 'ctag': 'CD', 'tag': 'CD', 'feats': '_', 'head': 6, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'nummod', 'start': 39, 'end': 41}), (6, {'address': 6, 'word': 'mg', 'lemma': 'mg', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {'nummod': [5]}), 'rel': 'compound', 'start': 43, 'end': 44}), (13, {'address': 13, 'word': 'AUC', 'lemma': 'auc', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 1, 'deps': defaultdict(<class 'list'>, {'compound': [6, 10, 12], 'amod': [9, 11], 'appos': [17], 'conj': [20], 'dep': [23]}), 'rel': 'dep', 'start': 95, 'end': 97}), (7, {'address': 7, 'word': 'twice', 'lemma': 'twice', 'ctag': 'RB', 'tag': 'RB', 'feats': '_', 'head': 8, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'advmod', 'start': 46, 'end': 50}), (8, {'address': 8, 'word': 'daily', 'lemma': 'daily', 'ctag': 'RB', 'tag': 'RB', 'feats': '_', 'head': 9, 'deps': defaultdict(<class 'list'>, {'advmod': [7]}), 'rel': 'advmod', 'start': 52, 'end': 56}), (9, {'address': 9, 'word': 'increased', 'lemma': 'increase', 'ctag': 'VBN', 'tag': 'VBN', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {'advmod': [8]}), 'rel': 'amod', 'start': 58, 'end': 66}), (10, {'address': 10, 'word': 'retapamulin', 'lemma': 'retapamulin', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'compound', 'start': 68, 'end': 78}), (11, {'address': 11, 'word': 'geometric', 'lemma': 'geometric', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 80, 'end': 88}), (12, {'address': 12, 'word': 'mean', 'lemma': 'mean', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'compound', 'start': 90, 'end': 93}), (14, {'address': 14, 'word': '(', 'lemma': '(', 'ctag': '-LRB-', 'tag': '-LRB-', 'feats': '_', 'head': 17, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'punct', 'start': 98, 'end': 98}), (17, {'address': 17, 'word': '24', 'lemma': '24', 'ctag': 'CD', 'tag': 'CD', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {'punct': [14, 18], 'nummod': [15], 'dep': [16]}), 'rel': 'appos', 'start': 101, 'end': 102}), (15, {'address': 15, 'word': '0', 'lemma': '0', 'ctag': 'CD', 'tag': 'CD', 'feats': '_', 'head': 17, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'nummod', 'start': 40, 'end': 40}), (16, {'address': 16, 'word': '-', 'lemma': '-', 'ctag': 'SYM', 'tag': 'SYM', 'feats': '_', 'head': 17, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'dep', 'start': 2, 'end': 2}), (18, {'address': 18, 'word': ')', 'lemma': ')', 'ctag': '-RRB-', 'tag': '-RRB-', 'feats': '_', 'head': 17, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'punct', 'start': 103, 'end': 103}), (19, {'address': 19, 'word': 'and', 'lemma': 'and', 'ctag': 'CC', 'tag': 'CC', 'feats': '_', 'head': 20, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'cc', 'start': 105, 'end': 107}), (20, {'address': 20, 'word': 'Cmax', 'lemma': 'cmax', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {'cc': [19], 'nmod': [22]}), 'rel': 'conj', 'start': 109, 'end': 112}), (21, {'address': 21, 'word': 'by', 'lemma': 'by', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 22, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 114, 'end': 115}), (22, {'address': 22, 'word': '81', 'lemma': '81', 'ctag': 'CD', 'tag': 'CD', 'feats': '_', 'head': 20, 'deps': defaultdict(<class 'list'>, {'case': [21]}), 'rel': 'nmod', 'start': 117, 'end': 118}), (23, {'address': 23, 'word': '<percentage>', 'lemma': '<percentage>', 'ctag': 'ADD', 'tag': 'ADD', 'feats': '_', 'head': 13, 'deps': defaultdict(<class 'list'>, {'nmod': [26]}), 'rel': 'dep', 'start': 119, 'end': 130}), (24, {'address': 24, 'word': 'after', 'lemma': 'after', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 26, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 132, 'end': 136}), (26, {'address': 26, 'word': 'application', 'lemma': 'application', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 23, 'deps': defaultdict(<class 'list'>, {'case': [24], 'amod': [25], 'nmod': [29], 'punct': [30], 'appos': [32]}), 'rel': 'nmod', 'start': 146, 'end': 156}), (25, {'address': 25, 'word': 'topical', 'lemma': 'topical', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 26, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 138, 'end': 144}), (27, {'address': 27, 'word': 'of', 'lemma': 'of', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 29, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 18, 'end': 19}), (29, {'address': 29, 'word': 'ointment', 'lemma': 'ointment', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 26, 'deps': defaultdict(<class 'list'>, {'case': [27], 'compound': [28]}), 'rel': 'nmod', 'start': 173, 'end': 180}), (28, {'address': 28, 'word': 'retapamulin', 'lemma': 'retapamulin', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 29, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'compound', 'start': 68, 'end': 78}), (30, {'address': 30, 'word': ',', 'lemma': ',', 'ctag': ',', 'tag': ',', 'feats': '_', 'head': 26, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'punct', 'start': 181, 'end': 181}), (31, {'address': 31, 'word': '1', 'lemma': '1', 'ctag': 'CD', 'tag': 'CD', 'feats': '_', 'head': 32, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'nummod', 'start': 118, 'end': 118}), (32, {'address': 32, 'word': '<percentage>', 'lemma': '<percentage>', 'ctag': 'ADD', 'tag': 'ADD', 'feats': '_', 'head': 26, 'deps': defaultdict(<class 'list'>, {'nummod': [31], 'nmod': [36]}), 'rel': 'appos', 'start': 119, 'end': 130}), (33, {'address': 33, 'word': 'on', 'lemma': 'on', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 36, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 15, 'end': 16}), (36, {'address': 36, 'word': 'skin', 'lemma': 'skin', 'ctag': 'NN', 'tag': 'NN', 'feats': '_', 'head': 32, 'deps': defaultdict(<class 'list'>, {'case': [33], 'det': [34], 'amod': [35], 'nmod': [40]}), 'rel': 'nmod', 'start': 212, 'end': 215}), (34, {'address': 34, 'word': 'the', 'lemma': 'the', 'ctag': 'DT', 'tag': 'DT', 'feats': '_', 'head': 36, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'det', 'start': 200, 'end': 202}), (35, {'address': 35, 'word': 'abraded', 'lemma': 'abraded', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 36, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 204, 'end': 210}), (37, {'address': 37, 'word': 'of', 'lemma': 'of', 'ctag': 'IN', 'tag': 'IN', 'feats': '_', 'head': 40, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'case', 'start': 18, 'end': 19}), (40, {'address': 40, 'word': 'males', 'lemma': 'male', 'ctag': 'NNS', 'tag': 'NNS', 'feats': '_', 'head': 36, 'deps': defaultdict(<class 'list'>, {'case': [37], 'amod': [38, 39]}), 'rel': 'nmod', 'start': 234, 'end': 238}), (38, {'address': 38, 'word': 'healthy', 'lemma': 'healthy', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 40, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 220, 'end': 226}), (39, {'address': 39, 'word': 'adult', 'lemma': 'adult', 'ctag': 'JJ', 'tag': 'JJ', 'feats': '_', 'head': 40, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'amod', 'start': 228, 'end': 232}), (41, {'address': 41, 'word': '.', 'lemma': '.', 'ctag': '.', 'tag': '.', 'feats': '_', 'head': 1, 'deps': defaultdict(<class 'list'>, {}), 'rel': 'punct', 'start': 239, 'end': 239})])\n"
     ]
    }
   ],
   "source": [
    "# tree = analyze(\"Interaction between oxytocin and antidiuretic hormone and its effect on the milk secretion by alveoli of the mammary gland of lactating rats.\")\n",
    "# print(tree.nodes.items())\n",
    "s2 = \"Co-administration of oral ketoconazole 200 mg twice daily increased retapamulin geometric mean AUC(0-24) and Cmax by 81% after topical application of retapamulin ointment, 1% on the abraded skin of healthy adult males. \"\n",
    "tree = analyze(s2)\n",
    "print(tree.nodes.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interaction(analysis, entities, e1, e2):\n",
    "    '''\n",
    "    Task:\n",
    "        Decide whether a sentence is expressing a DDI between two drugs.\n",
    "    \n",
    "    Input:\n",
    "        analysis: a DependencyGraph object with all sentence information\n",
    "        entities: a list of all entities in the sentence (id and offsets)\n",
    "        e1, e2: ids of the two entities to be checked\n",
    "    \n",
    "    Output:\n",
    "        Returns the type of interaction ('effect', 'mechanism', 'advice', 'int') between e1 and e2\n",
    "        expressed by the sentence, or 'None' if no interaction is described.\n",
    "    '''\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = \"output.txt\"\n",
    "datadir = \"../../labAHLT/data/devel\"\n",
    "\n",
    "# process each file in directory\n",
    "for f in listdir (datadir):\n",
    "    # parse XML file , obtaining a DOM tree\n",
    "    tree = parse ( datadir + \"/\" + f)\n",
    "    # process each sentence in the file\n",
    "    sentences = tree.getElementsByTagName(\"sentence\")\n",
    "    for s in sentences:\n",
    "\n",
    "        sid = s.attributes [\"id\"].value # get sentence id\n",
    "        stext = s.attributes [\"text\"].value # get sentence text\n",
    "        \n",
    "        # CoreNLP throws error for empty sentences\n",
    "        if len(stext) == 0:\n",
    "            continue\n",
    "\n",
    "        # load sentence entities into a dictionary\n",
    "        entities = {}\n",
    "        ents = s.getElementsByTagName(\"entity\")\n",
    "        for e in ents:\n",
    "            eid = e . attributes [\"id\"].value\n",
    "            entities[eid] = e.attributes[\"charOffset\"].value.split(\"-\")\n",
    "\n",
    "        # Tokenize, tag, and parse sentence\n",
    "        analysis = analyze(stext)\n",
    "\n",
    "        # for each pair in the sentence , decide whether it is DDI and its type\n",
    "        pairs = s.getElementsByTagName(\"pair\")\n",
    "        for p in pairs:\n",
    "            id_e1 = p.attributes[\"e1\"].value\n",
    "            id_e2 = p.attributes[\"e2\"].value\n",
    "            ddi_type = check_interaction(analysis, entities , id_e1 , id_e2 )\n",
    "            if ddi_type != None :\n",
    "                print (sid +\"|\"+ id_e1 +\"|\"+ id_e2 +\"|\"+ ddi_type, file = outf )\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StanfordCoreNLP throws error 500 when a sentence contains '%':\n",
    "#    Illegal hex characters in escape (%) pattern - Error at index 0 in: \" a\"\n",
    "#  java.base/java.net.URLDecoder.decode(URLDecoder.java:232)\n",
    "#  java.base/java.net.URLDecoder.decode(URLDecoder.java:142)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
